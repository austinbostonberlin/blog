<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>RPC on Random Thoughts</title><link>https://blog.joway.io/tags/rpc/</link><description>Recent content in RPC on Random Thoughts</description><generator>Hugo -- gohugo.io</generator><language>cn</language><lastBuildDate>Thu, 06 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://blog.joway.io/tags/rpc/index.xml" rel="self" type="application/rss+xml"/><item><title>RPC 漫谈： 连接问题</title><link>https://blog.joway.io/posts/deep-into-rpc-connection/</link><pubDate>Thu, 06 May 2021 00:00:00 +0000</pubDate><guid>https://blog.joway.io/posts/deep-into-rpc-connection/</guid><description>什么是连接 在物理世界并不存在连接这么一说，数据转换为光/电信号后，从一台机器发往另一台机器，中间设备通过信号解析出目的信息来确定如何转发包。我们日常所谓的「连接」纯粹是一个人为抽象的概念，目的是将传输进来的无状态数据通过某个固定字段作为标识，分类为不同有状态会话，从而方便在传输层去实现一些依赖状态的事情。
以 TCP 为例，一开始的三次握手用来在双方确认一个初始序列号（Initial Sequence Numbers，ISN），这个 ISN 标志了一个 TCP 会话，并且这个会话有一个独占的五元组（源 IP 地址，源端口，目的 IP 地址，目的端口，传输层协议）。在物理意义上，一个 TCP 会话等价于通往某一个服务器的相对固定路线（即固定的中间物理设备集合），正是由于这样，我们去针对每个 TCP 会话进行有状态的拥塞控制等操作才是有意义的。
连接的开销 我们常常听到运维会说某台机器连接太多所以出现了服务抖动，大多数时候我们会接受这个说法然后去尝试降低连接数。然而我们很少去思考一个问题，在一个服务连接数过多的时候，机器上的 CPU，内存，网卡往往都有大量的空余资源，为什么还会抖动？维护一个连接的具体开销是哪些？
内存开销：
TCP 协议栈一般由操作系统实现，因为连接是有状态对，所以操作系统需要在内存中保存这个会话信息，这个内存开销每个连接大概 4kb 不到。
文件描述符占用：
在 Linux 视角中，每个连接都是一个文件，都会占用一个文件描述符。文件描述符所占用的内存已经计算在上面的内存开销中，但操作系统为了保护其自身的稳定性和安全性，会限制整个系统内以及每个进程中可被同时打开的最大文件描述符数：
# 机器配置: Linux 1 核 1 GB $ cat /proc/sys/fs/file-max 97292 $ ulimit -n 1024 上面的设置表示整个操作系统最多能同时打开 97292 个文件，每个进程最多同时打开 1024 个文件。
严格来说文件描述符根本算不上是一个资源，真正的资源是内存。如果你有明确的需要，完全可以通过设置一个极大值，让所有应用绕开这个限制。
线程开销：
有一些较老的 Server 实现采用的还是为每个连接独占（新建或从连接池中获取）一个线程提供服务的方式，对于这类服务来说，除了连接本身占用的外，还有线程的固定内存开销：
# 机器配置: Linux 1 核 1 GB # 操作系统最大线程数 $ cat /proc/sys/kernel/threads-max 7619 # 操作系统单进程最大线程数，undef 表示未限制 $ cat /usr/include/bits/local_lim.</description></item><item><title>RPC 漫谈：序列化问题</title><link>https://blog.joway.io/posts/deep-into-rpc-serialization/</link><pubDate>Fri, 30 Apr 2021 00:00:00 +0000</pubDate><guid>https://blog.joway.io/posts/deep-into-rpc-serialization/</guid><description>何为序列 对于计算机而言，一切数据皆为二进制序列。但编程人员为了以人类可读可控的形式处理这些二进制数据，于是发明了数据类型和结构的概念，数据类型用以标注一段二进制数据的解析方式，数据结构用以标注多段(连续/不连续)二进制数据的组织方式。
例如以下程序结构体：
type User struct { Name string Email string } Name 和 Email 分别表示两块独立(或连续，或不连续)的内存空间（数据），结构体变量本身也有一个内存地址。
在单进程中，我们可以通过分享该结构体地址来交换数据。但如果要将该数据通过网络传输给其他机器的进程，我们需要现将该 User 对象中不同的内存空间，编码成一段连续二进制表示，此即为「序列化」。而对端机器收到了该二进制流以后，还需要能够认出该数据为 User 对象，解析为程序内部表示，此即为「反序列化」。
序列化和反序列化，就是将同一份数据，在人的视角和机器的视角之间相互转换。
序列化过程 定义接口描述（IDL） 为了传递数据描述信息，同时也为了多人协作的规范，我们一般会将描述信息定义在一个由 IDL(Interface Description Languages) 编写的定义文件中，例如下面这个 Protobuf 的 IDL 定义：
message User { string name = 1; string email = 2; } 生成 Stub 代码 无论使用什么样的序列化方法，最终的目的是要变成程序中里的一个对象，虽然序列化方法往往是语言无关的，但这段将内存空间与程序内部表示（如 struct/class）相绑定的过程却是语言相关的，所以很多序列化库才会需要提供对应的编译器，将 IDL 文件编译成目标语言的 Stub 代码。
Stub 代码内容一般分为两块：
类型结构体生成（即目标语言的 Struct[Golang]/Class[Java] ） 序列化/反序列化代码生成（将二进制流与目标语言结构体相转换） 下面是一段 Thrift 生成的的序列化 Stub 代码：
type User struct { Name string `thrift:&amp;#34;name,1&amp;#34; db:&amp;#34;name&amp;#34; json:&amp;#34;name&amp;#34;` Email string `thrift:&amp;#34;email,2&amp;#34; db:&amp;#34;email&amp;#34; json:&amp;#34;email&amp;#34;` } //写入 User struct func (p *User) Write(oprot thrift.</description></item><item><title>RPC 漫谈： 限流问题</title><link>https://blog.joway.io/posts/deep-into-rpc-ratelimiter/</link><pubDate>Fri, 23 Apr 2021 00:00:00 +0000</pubDate><guid>https://blog.joway.io/posts/deep-into-rpc-ratelimiter/</guid><description>微服务之间的 RPC 调用往往会使用到限流功能，但是很多时候我们都是用很简单的限流策略，亦或是工程师拍脑袋定一个限流值。
这篇文章主要讨论在 RPC 限流中，当前存在的问题和可能的解决思路。
为什么需要限流 避免连锁崩溃 一个服务即便进行过压测，但当真实运行到线上时，其收到的请求流量以及能够负载的流量是不固定的，如果服务自身没有一个自我保护机制，当流量超过预计的负载后，会将这部分负载传递给该服务的下游，造成连锁反应甚至雪崩。
提供可靠的响应时间 服务调用方一般都设有超时时间，如果一个服务由于拥塞，导致响应时间都处于超时状态，那么即便服务最终正确提供了响应，对于 Client 来说也完全没有意义。
一个服务对于调用方提供的承诺既包含了响应的结果，也包含了响应的时间。限流能够让服务自身通过主动丢弃负载能力外的流量，以达到在额定负载能力下，依然能够维持有效的响应效率。
传统方案 漏斗 优点：
能够强制限制出口流量速率 缺点：
无法适应突发性流量 令牌桶 优点：
在统计上维持一个特定的平均速度 在局部允许短暂突发性流量通过 存在的问题 在两类传统方案中，都需要去指定一个固定值用以标明服务所能够接受的负载，但在现代的微服务架构中，一个服务的负载能力往往是会不断变化的，有以下几个常见的原因：
随着新增代码性能变化而变化 随着服务依赖的下游性能变化而变化 随着服务部署的机器(CPU/磁盘)性能变化而变化 随着服务部署的节点数变化而变化 随着业务需求变化而变化 随着一天时间段变化而变化 通过人工声明一个服务允许的负载值，即便这个值是维护在配置中心可以动态变化，但依然是不可持续维护的，况且该值具体设置多少也极度依赖于人的个人经验和判断。甚至人自身的小心思也会被带入到这个值的选择中，例如 Server 会保守估计自己的能力，Client 会过多声明自己的需求，长期以往会导致最终的人为设定值脱离了实际情况。
什么是服务负载 当我们向一个服务发起请求时，我们关心的无外乎两点：
服务能够支撑的同时并发请求数 服务的响应时间 并发请求数 对于 Server 而言，有几个指标常常容易搞混：
当前连接数 当前接受的请求数 当前正在并发处理的请求数 QPS 连接数和请求数是 1:N 的关系。在现代 Server 的实现中，连接本身消耗的服务器资源已经非常少了（例如 Java Netty 实现，Go Net 实现等），而且一般对内网的服务而言，多路复用时，请求数变多也并不一定会导致连接数变多。
有些 Server 出于流量整形角度的考虑，并不一定会在收到请求以后，立马交给 Server 响应函数处理，而是先加入到一个队列中，等 Server 有闲置 Worker 后再去执行。所以这里就存在两类请求：接受的请求与正在处理的请求。
而 QPS 是一个统计指标，仅仅只表示每秒通过了多少请求。</description></item></channel></rss>